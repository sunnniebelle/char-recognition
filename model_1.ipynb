{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split='letters',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split='letters',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "def get_balanced_subset(dataset, samples_per_class=100):\n",
    "    data = dataset.data\n",
    "    targets = dataset.targets\n",
    "    selected_indices = []\n",
    "    for class_label in range(1, 27):\n",
    "        class_indices = (targets == class_label).nonzero(as_tuple=True)[0]\n",
    "        selected_indices.extend(class_indices[:samples_per_class].tolist())\n",
    "    return data[selected_indices], targets[selected_indices]\n",
    "\n",
    "X_train_tensor, y_train = get_balanced_subset(train_dataset, samples_per_class=100)\n",
    "X_test_tensor, y_test = get_balanced_subset(test_dataset, samples_per_class=40)\n",
    "\n",
    "X_train = X_train_tensor.float().view(-1, 28*28).numpy() / 255.0\n",
    "X_test = X_test_tensor.float().view(-1, 28*28).numpy() / 255.0\n",
    "y_train = y_train.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "print(\"Training dictionary learning model (this may take a few minutes)...\")\n",
    "dict_learner = DictionaryLearning(\n",
    "    n_components=500,        # number of dictionary atoms\n",
    "    alpha=1,                 # sparsity controlling parameter\n",
    "    max_iter=500,\n",
    "    transform_algorithm='lasso_lars',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_train_sparse = dict_learner.fit_transform(X_train)\n",
    "X_test_sparse = dict_learner.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "print(\"Training logistic regression with SGD...\")\n",
    "clf = SGDClassifier(loss='log_loss', penalty='l2', max_iter=1000, tol=1e-3, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
